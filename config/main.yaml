defaults:
  - override hydra/launcher: joblib

seed: 42
train_test_ratio: 0.7
noisy_train_set: True
repo_root: "/home/pl22767/Project/MMDA/"
# repo_root: "/home/po-han/Desktop/Projects/MMDA/"

dataset: "MSRVTT"
dataset_level_datasets: [pitts, imagenet, cosmos, sop, tiil, musiccaps, flickr]
class_level_datasets: [sop]
object_level_datasets: [pitts, sop]
mislabeled_datasets: [imagenet, cosmos, tiil]
retrieval_datasets: [flickr]
any_retrieval_datasets: [KITTI, MSRVTT, BTC]
shuffle_llava_datasets: [pitts, sop] # datasets whose plots contains llava
mislabel_llava_datasets: [imagenet]
classification_datasets: [imagenet, leafy_spurge]
dataset_size: {
  sop: 56222,
  musiccaps: 5397,
  imagenet: 50_000,
  tiil: 14276,
  cosmos: 44406,
  pitts: 17608,
  flickr: 155070
}

BTC:
  retrieval_dim: 50
  equal_weights: False
  img_encoder: ""
  audio_encoder: ""
  horizon: 120
  mask_ratio: 4 # ratio of the missing data : size of test data
  paths:
    dataset_path: "/nas/timeseries/timeseries_synthesis/sameep_store/btc/split_fresh_large_120/"
    save_path: ${BTC.paths.dataset_path}
    plots_path: ${repo_root}plots/BTC/


MSRVTT:
  img_encoder: "clip"
  audio_encoder: "clap"
  retrieval_dim: "" # we use all the dimensions for retrieval
  mask_ratio: 4 # ratio of the missing data : size of test data
  paths:
    dataset_path: "/nas/pohan/datasets/MSR-VTT/"
    # dataset_path: "/home/po-han/Downloads/MSR-VTT/"
    save_path: ${MSRVTT.paths.dataset_path}embeddings/
    plots_path: ${repo_root}plots/MSR-VTT/

KITTI:
  sim_dim: 256 # dimension of the CCA transformation
  retrieval_dim: 10 # dimension of the similarity score
  equal_weights: False
  img_encoder: "liploc"
  lidar_encoder: "liploc"
  text_encoder: "gtr"
  shuffle_step: 20
  mask_ratio: 2 # ratio of the missing data : size of test data
  paths:
    dataset_path: "/nas/pohan/datasets/KITTI/"
    save_path: ${KITTI.paths.dataset_path}embeddings/
    plots_path: ${repo_root}plots/KITTI/

sop:
  sim_dim: 150 # dimension of the similarity score and the CCA transformation
  equal_weights: False
  text_encoder: "clip"
  img_encoder: "clip"
  paths:
    # repo_root: "/home/po-han/Desktop/Projects/MMDA/"
    dataset_path: "/nas/omama/datasets/Stanford_Online_Products/"
    # dataset_path: "/home/po-han/Downloads/datasets/Stanford_Online_Products/"
    save_path: "/nas/tirr/SOP/"
    # save_path: "/home/po-han/Downloads/SOP/"
    plots_path: ${repo_root}plots/Stanford_Online_Products/
  work_dir: ${repo_root}hydra/${now:%Y-%m-%d}/${now:%H-%M-%S}

musiccaps:
  sim_dim: 25 # dimension of the similarity score and the CCA transformation
  equal_weights: False
  img_encoder: "clap" # 512
  text_encoder: "gtr"  # 768
  paths:
    dataset_path: "/nas/pohan/datasets/MusicCaps/wav_files/"
    save_path: ${musiccaps.paths.dataset_path}embeddings/
    plots_path: ${repo_root}plots/MusicCaps/

imagenet:
  sim_dim: 700 # dimension of the similarity score and the CCA transformation
  equal_weights: False
  img_encoder: "dino"
  text_encoder: "gtr"
  train_test_ratios: [0.7] #, 0.3, 0.5, 0.7]
  shuffle_ratios: [0.1, 0.3, 0.5, 0.7, 1.0]
  shuffle: False
  paths:
    dataset_path: "/nas/pohan/datasets/ImageNet/"
    save_path: ${imagenet.paths.dataset_path}embeddings/
    plots_path: ${repo_root}plots/ImageNet/
    label_embeddings: ${imagenet.paths.dataset_path}_${text_encoder}_label_embeddings.npy

leafy_spurge:
  sim_dim: 700 # dimension of the similarity score and the CCA transformation
  equal_weights: False
  img_encoder: "dino"
  text_encoder: "gtr"
  train_test_ratios: [0.4, 0.6, 0.7, 0.888]
  paths:
    dataset_path: "/nas/pohan/datasets/Leafy/"
    save_path: ${leafy_spurge.paths.dataset_path}embeddings/
    plots_path: ${repo_root}plots/Leafy/
    label_embeddings: ${leafy_spurge.paths.dataset_path}_${text_encoder}_label_embeddings.npy

tiil:
  sim_dim: 200 # dimension of the similarity score and the CCA transformation
  equal_weights: False
  img_encoder: "clip"
  text_encoder: "gtr"
  paths:
    dataset_path: "/nas/pohan/datasets/tiil/"
    save_path: ${tiil.paths.dataset_path}embeddings/
    plots_path: ${repo_root}plots/TIIL/

cosmos:
  sim_dim: 700 # dimension of the similarity score and the CCA transformation
  detection_rule: "bilevel" # bilevel, mean
  equal_weights: False
  img_encoder: "dino"
  text_encoder: "gtr"
  paths:
    dataset_path: "/nas/pohan/datasets/COSMOS/"
    save_path: ${cosmos.paths.dataset_path}embeddings/
    plots_path: ${repo_root}plots/COSMOS/

pitts:
  sim_dim: 10 # dimension of the similarity score and the CCA transformation
  equal_weights: False
  img_encoder: "cosplace"
  text_encoder: "gtr"
  paths:
    dataset_path: "/nas/pohan/datasets/pitts250k/"
    save_path: ${pitts.paths.dataset_path}embeddings/
    plots_path: ${repo_root}plots/PITTS/

flickr:
  sim_dim: 200 # dimension of the similarity score and the CCA transformation
  cca_proj_dims: [10, 50, 100, 200, 500, 750]
  equal_weights: False
  img2text: True # whether to retrieve text to image or image to text
  img_encoder: "dino"
  text_encoder: "gtr"
  paths:
    dataset_path: "/nas/pohan/datasets/flickr30k/"
    save_path: ${flickr.paths.dataset_path}embeddings/
    plots_path: ${repo_root}plots/Flickr30k/

hydra:
  run:
    dir: ${repo_root}hydra/${dataset}/${now:%Y-%m-%d}/${now:%H-%M-%S}

llava:
  model_path: '/nas/omama/llava-v1.5-13b'
  model_base: null
  num_gpus: 6
  conv_mode: null
  temperature: 0.2
  max_new_tokens: 512
  load_8bit: True
  load_4bit: False
  debug: False
  num_processes: 6

asif:  # Hyperparameters of asif baseline
  non_zeros: 800
  val_exps: [8]
  max_gpu_mem_gb: 23

# model embedding size
# clap: 512
# gtr: 768
# dino: 1536
# clip: 1280 (1024 for msrvtt)
# liploc: 256
# imagebind: 1024